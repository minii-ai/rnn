{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rnn\n",
    "\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2024/02/image-80.png)\n",
    "\n",
    "_For those interested in how the forward and backward pass works._\n",
    "\n",
    "RNNs are a type of neural net that operate on sequences. They use a hidden state vector and an input vector to predict an output vector (ie. probabilities over tokens) and the next hidden state. The next hidden state is used to predict the next token, so on and so forth. The recurrence relationship, where the next hidden state depends on the previous hidden state gives them the name **Recurrent Neural Nets**.\n",
    "\n",
    "## Forward Pass\n",
    "\n",
    "RNNs have a simple API. They take in a hidden state vector and an input vector to produce an output vector and the next hidden state.\n",
    "\n",
    "**Weights and Bias Matrices**\n",
    "$$W_{xh}\\in ({n \\times m}), \\ W_{hh} \\in ({n \\times n}), b_h \\in ({1 \\times n}) $$\n",
    "$$W_{hy} \\in ({l \\times n}), b_y \\in ({1 \\times l})$$\n",
    "\n",
    "**Input Vector**\n",
    "$$x_t \\in ({1 \\times m})$$\n",
    "\n",
    "**Hidden State Vector**\n",
    "$$h_t \\in ({1 \\times n})$$\n",
    "\n",
    "**Foward Pass**\n",
    "\n",
    "We have all the ingredients for the forward pass! Our choice of activation is `tanh` and `softmax`. Tanh squeezes the activations between -1 and 1 and softmax gives us output probabilities.\n",
    "\n",
    "$$\n",
    "z_t^h = x_tW_{xh}^{T} + h_{t-1}W_{hh}^{T} + b_h\n",
    "$$\n",
    "\n",
    "$$\n",
    "h_t = \\tanh(a_t)\n",
    "$$\n",
    "\n",
    "$$\n",
    "z_t^y = h_tW_{hy}^{T} + b_y\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y}_t = \\text{softmax}(b_t)\n",
    "$$\n",
    "\n",
    "## Backward Pass\n",
    "\n",
    "After the forward pass, we'll compute the loss and gradients of the weight and bias matrices. Then do gradient descent.\n",
    "\n",
    "### Loss\n",
    "\n",
    "We use cross entropy loss between the predicted token probability and the target token across all time steps.\n",
    "\n",
    "$$\n",
    "L = \\sum_{t=1}^{T}L_t(\\hat{y}_t, y_t) = \\sum_{t=1}^{T}{\\sum_{i = 1}^{C}-y_t^i\n",
    "\\log(\\hat{y}_t^i)}\n",
    "$$\n",
    "\n",
    "### Backpropagation Through Time\n",
    "\n",
    "Source: https://phillipi.github.io/6.882/2020/notes/6.036_notes.pdf\n",
    "\n",
    "The hardest part is keeping track of matrix shapes. Do multiply the shapes of the partials to check if the shapes make sense. Don't memorize. You can derive everything from first principles just by following the RNN section of the textbook above. Phillip Isola does an amazing job at explaining how to implement BPTT and where the gradients come from. \n",
    "\n",
    "Hopefully you'll come to the same result! My derivation is slightly different because I use row vectors instead of column vectors $x_t \\in (1 \\times m)$.\n",
    "\n",
    "Just peel back each layer and apply the chain rule.\n",
    "\n",
    "\n",
    "#### Gradient of Loss w.r.t $z_t^y$\n",
    "\n",
    "https://cs231n.github.io/neural-networks-case-study/#grad\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L_t}{\\partial z_t^y} = \\hat{y_t} - y_t\n",
    "$$\n",
    "\n",
    "$$(1 \\times l) = (1 \\times l) - (1 \\times l)$$\n",
    "\n",
    "#### Gradient of Tanh\n",
    "$$\\frac{\\partial \\tanh(u)}{\\partial u} = 1 - \\tanh(u)^2$$\n",
    "\n",
    "#### Gradient of 1st Layer\n",
    "\n",
    "Gradient of the $W_{hy}$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{hy}} = \\sum_{t=1}^T \\frac{\\partial L_t}{\\partial z_t^y}\\frac{\\partial z_t^y}{\\partial W_{hy}} = \\sum_{t=1}^T (\\frac{\\partial L_t}{\\partial z_t^y})^T h_t\n",
    "$$\n",
    "\n",
    "$$\n",
    "(l \\times n) = (l \\times 1) \\times (1 \\times n)\n",
    "$$\n",
    "\n",
    "Gradient of the $b_y$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_y} = \\sum_{t=1}^T \\frac{\\partial L_t}{\\partial z_t^y}\\frac{\\partial z_t^y}{\\partial b_y} = \\frac{\\partial L_t}{\\partial z_t^y}\n",
    "$$\n",
    "\n",
    "$$\n",
    "(1 \\times l) = (1 \\times l)\n",
    "$$\n",
    "\n",
    "\n",
    "#### Gradients of 2nd Layer\n",
    "\n",
    "This is the most tricky layer. Let's define some terms which will be useful.\n",
    "\n",
    "#### Definitions\n",
    "\n",
    "We'll be taking gradients of the future loss with respect to a hidden state. The future loss is defined as follows. Note the recurrence in the definition (we can write $F_{t-1}$ in terms of $F_t$).\n",
    "\n",
    "$$F_t = \\sum_{u = t + 1}^TL_u$$\n",
    "\n",
    "$$F_{t - 1} = L_t + \\sum_{u = t + 1}^TL_u = L_t + F_t$$\n",
    "\n",
    "#### Gradient of Future Loss w.r.t hidden state\n",
    "\n",
    "$$\n",
    "\\delta^{h_{t-1}} = \\frac{\\partial F_{t-1}}{\\partial h_{t-1}} \n",
    "= \\frac{\\partial}{\\partial h_{t-1}} {\\sum_{u = t}^TL_u} \n",
    "= \\frac{\\partial}{\\partial h_t} {\\sum_{u = t}^TL_u} \\frac{\\partial h_t}{\\partial h_{t-1}}\n",
    "= (\\frac{\\partial L_t}{\\partial h_t} + \\frac{\\partial}{\\partial h_t}\\sum_{u = t + 1}^TL_u) \\frac{\\partial h_t}{\\partial h_{t-1}}\n",
    "= (\\frac{\\partial L_t}{\\partial h_t} + \\delta^{h_t}) \\frac{\\partial h_t}{\\partial h_{t-1}} = \\frac{\\partial F_{t-1}}{\\partial h_t} \\frac{\\partial h_t}{\\partial h_{t-1}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "(1 \\times n)\n",
    "$$\n",
    "\n",
    "Note that $\\frac{\\partial L_t}{\\partial h_t} + \\delta^{h_t} = \\frac{\\partial F_{t-1}}{\\partial h_t}$.\n",
    "\n",
    "\n",
    "Also note that $\\frac{\\partial F_T}{\\partial h_T} = 0 \\in (1 \\times n)$ because there $L_{T+1} ...$ do not exist. $L_T$ is the loss at the final timestep, so the final hidden state $h_T$ will have no effect on future losses, hence the zero gradient. \n",
    "\n",
    "#### Gradient of Loss w.r.t hidden state\n",
    "$$\n",
    "\\frac{\\partial L_t}{\\partial h_t} = \\frac{\\partial L_t}{\\partial z_t^y}\\frac{\\partial z_t^y}{\\partial h_t} = \\frac{\\partial L_t}{\\partial z_t^y} W_{hy}\n",
    "$$\n",
    "\n",
    "$$\n",
    "(1 \\times n) = (1 \\times l) \\times (l \\times n)\n",
    "$$\n",
    "\n",
    "#### Gradient of hidden state w.r.t to its input before activation $z_t^h$\n",
    "\n",
    "$$\\frac{\\partial h_t}{\\partial z_t^h} = 1 - h_t^2$$\n",
    "\n",
    "$$(1 \\times n)$$\n",
    "\n",
    "Really this is a $(n \\times n)$ diagonal matix but b/c $\\frac{\\partial h_t^i}{\\partial z_t^j} = 0$ when $i \\neq j$, I decided to grab diagonal and stuff it into a $(1 \\times n)$ row vector. The reason being activation are applied element-wise.\n",
    "\n",
    "\n",
    "#### Gradient of $F_{t-1}$ w.r.t hidden state\n",
    "\n",
    "Everything is going to come together nicely now. This is just the sum of 2 gradients we defined above.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial F_{t-1}}{\\partial h_t} = \\frac{\\partial L_t}{\\partial h_t} + \\frac{\\partial}{\\partial h_t} \\sum_{u = t + 1}^TL_u = \\frac{\\partial L_t}{\\partial h_t} + \\delta^{h_t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "(1 \\times n) = (1 \\times n) + (1 \\times n)\n",
    "$$\n",
    "\n",
    "\n",
    "#### Gradient of $F_{t-1}$ w.r.t $z_t^h$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial F_{t-1}}{\\partial z_t^h} = \\frac{\\partial F_{t-1}}{\\partial h_t} \\frac{\\partial h_t}{\\partial z_t^h}\n",
    "$$\n",
    "\n",
    "$$\n",
    "(1 \\times n) = (1 \\times n) \\times (1 \\times n)\n",
    "$$\n",
    "\n",
    "\n",
    "#### Gradient of hidden state weight matrices\n",
    "\n",
    "Let's calculate them now!\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{xh}} = \\sum_{t=1}^{T} \\frac{\\partial F_{t-1}}{\\partial h_t} \\frac{\\partial h_t}{\\partial z_t^h} \\frac{\\partial z_t^h}{\\partial W_{xh}} = \\sum_{t=1}^T (\\frac{\\partial F_{t-1}}{\\partial z_t^h})^T x_t\n",
    "$$\n",
    "\n",
    "$$\n",
    "(n \\times m) = (n \\times 1) \\times (1 \\times m)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{hh}} = \\sum_{t=1}^{T} \\frac{\\partial F_{t-1}}{\\partial h_t} \\frac{\\partial h_t}{\\partial z_t^h} \\frac{\\partial z_t^h}{\\partial W_{xh}} = \\sum_{t=1}^T (\\frac{\\partial F_{t-1}}{\\partial z_t^h})^T h_{t-1}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "(n \\times n) = (n \\times 1) \\times (1 \\times n)\n",
    "$$\n",
    "\n",
    "#### Gradient of hidden state bias vector\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_{h}} = \\sum_{t=1}^{T} \\frac{\\partial F_{t-1}}{\\partial h_t} \\frac{\\partial h_t}{\\partial z_t^h} \\frac{\\partial z_t^h}{\\partial b_h} = \\sum_{t=1}^T \\frac{\\partial F_{t-1}}{\\partial z_t^h}\n",
    "$$\n",
    "\n",
    "$$\n",
    "(1 \\times n) = (1 \\times n)\n",
    "$$\n",
    "\n",
    "#### Computing $\\delta^h_{t-1}$\n",
    "At timestep $t$ to compute $\\frac{\\partial F_{t-1}}{\\partial h_t}$, we need $\\delta^h_t$. For timestep $t-1$, we will need to compute $\\delta^h_{t-1}$. Let's revisit the definition of this gradient.\n",
    "\n",
    "$$\n",
    "\\delta^{h_{t-1}} = \\frac{\\partial F_{t-1}}{\\partial h_t} \\frac{\\partial h_t}{\\partial h_{t-1}}\n",
    "$$\n",
    "\n",
    "Let's apply the chain rule to $\\frac{\\partial h_t}{\\partial h_{t-1}}$. \n",
    "\n",
    "$$\n",
    "\\delta^{h_{t-1}} = \\frac{\\partial F_{t-1}}{\\partial h_t} \\frac{\\partial h_t}{\\partial z_t^h}\\frac{\\partial z_t^h}{\\partial h_{t-1}}\n",
    "$$\n",
    "\n",
    "Simplify.\n",
    "\n",
    "$$\n",
    "\\delta^{h_{t-1}} = \\frac{\\partial F_{t-1}}{\\partial z_t^h} \\frac{\\partial z_t^h}{\\partial h_{t-1}} = \\frac{\\partial F_{t-1}}{\\partial z_t^h} W_{hh}\n",
    "$$\n",
    "\n",
    "$$(1 \\times n) = (1 \\times n) \\times (n \\times n)$$\n",
    "\n",
    "We now have everything we need to implement backprop. In `rnn.py` we will translate all of this to code.\n",
    "\n",
    "### Gradient Descent\n",
    "\n",
    "We'll implement a version of gradient descent called Adagrad. One of the common problems training RNNs are the exploding vanishing gradients. Adagrad *adapts* our learning rate so that we take smaller steps when the gradients are big and bigger steps when gradients are small. This improves our training stability significantly. In fact, using vanilla stochastic gradient descent, training does not converge.\n",
    "\n",
    "$$\n",
    "g_t = \\nabla_{\\theta} L(\\theta_t)\n",
    "$$\n",
    "$$\n",
    "G_t = G_{t-1} + g_t^2\n",
    "$$\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} g_t\n",
    "$$\n",
    "\n",
    "We implement this in `train.py`.\n",
    "\n",
    "## Resources\n",
    "Would not have made it without these. Read them.\n",
    "\n",
    "- https://phillipi.github.io/6.882/2020/notes/6.036_notes.pdf\n",
    "- https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks\n",
    "- https://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "- https://gist.github.com/karpathy/d4dee566867f8291f086\n",
    "- https://cs231n.github.io/neural-networks-case-study/#grad\n",
    "- https://explained.ai/matrix-calculus/\n",
    "- https://www.youtube.com/watch?v=0XdPIqi0qpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z, t: float = 1.0):\n",
    "    \"\"\"Softmax w/ temperature t\"\"\"\n",
    "    z_exp = np.exp(z / t)\n",
    "    return z_exp / np.sum(z_exp)\n",
    "\n",
    "\n",
    "class RNN:\n",
    "    \"\"\"Vanilla character-level RNN in numpy\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size: int, vocab: list[str]):\n",
    "        \"\"\"\n",
    "        Initialize the weight and bias matrices\n",
    "\n",
    "        Params:\n",
    "            - hidden_size: hidden state dim\n",
    "            - vocab: list of unique chars\n",
    "        \"\"\"\n",
    "        # params + tokenizer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.start_token = \"<S>\"\n",
    "        self.eos_token = \"<EOS>\"\n",
    "        self.start_token_idx = 0\n",
    "        self.eos_token_idx = 1\n",
    "        self.vocab = [self.start_token, self.eos_token] + vocab\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.char_to_idx = {char: i for i, char in enumerate(self.vocab)}\n",
    "        self.idx_to_char = {i: char for i, char in enumerate(self.vocab)}\n",
    "\n",
    "        # weights\n",
    "        self.Wxh = np.random.randn(hidden_size, self.vocab_size) * 0.01\n",
    "        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "        self.Why = np.random.randn(self.vocab_size, hidden_size) * 0.01\n",
    "\n",
    "        # biases\n",
    "        self.bh = np.zeros((1, hidden_size))\n",
    "        self.by = np.zeros((1, self.vocab_size))\n",
    "\n",
    "        self.weights = (self.Wxh, self.Whh, self.Why, self.bh, self.by)\n",
    "        self.num_params = sum(w.size for w in self.weights)\n",
    "\n",
    "    def encode(self, chars: str):\n",
    "        \"\"\"Turns a string of chars into idxes\"\"\"\n",
    "        ids = (\n",
    "            [self.start_token_idx]\n",
    "            + [self.char_to_idx[char] for char in chars]\n",
    "            + [self.eos_token_idx]\n",
    "        )\n",
    "        return ids\n",
    "\n",
    "    def decode(self, idxes: list[int]):\n",
    "        \"\"\"Turns a list of idxes into chars\"\"\"\n",
    "        chars = [\n",
    "            self.idx_to_char[idx]\n",
    "            for idx in idxes\n",
    "            if idx != self.eos_token_idx and idx != self.start_token_idx\n",
    "        ]\n",
    "        return \"\".join(chars)\n",
    "\n",
    "    def __call__(self, x, h, t=1.0) -> np.ndarray:\n",
    "        \"\"\"RNN forward pass at softmax temperature t\"\"\"\n",
    "        assert x.shape == (1, self.vocab_size) and h.shape == (1, self.hidden_size)\n",
    "        zh = x @ self.Wxh.T + h @ self.Whh.T + self.bh\n",
    "        hnext = np.tanh(zh)\n",
    "        zy = hnext @ self.Why.T + self.by\n",
    "        y = softmax(zy, t)\n",
    "\n",
    "        return y, hnext\n",
    "\n",
    "    def sample(self, t: float = 1.0, n: int = 1000):\n",
    "        \"\"\"Generates unconditional samples with temperature t, with max tokens n\"\"\"\n",
    "        sample = []\n",
    "        for i in self.sample_progressive(t, n):\n",
    "            sample.append(i)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def sample_progressive(self, t: float = 1.0, n: int = 1000):\n",
    "        \"\"\"Generate one char at a time, starting at temperature t with max tokens n\"\"\"\n",
    "        x = np.zeros((1, self.vocab_size))\n",
    "        x[0, self.start_token_idx] = 1  # create one hot encoding for char\n",
    "        h = np.zeros((1, self.hidden_size))  # initialize hidden state to all 0s\n",
    "\n",
    "        for i in range(n):\n",
    "            probs, h = self(x, h, t)  # sample next token probs\n",
    "            idx = np.random.choice(self.vocab_size, p=probs.ravel())\n",
    "\n",
    "            x = np.zeros((1, self.vocab_size))\n",
    "            x[0, idx] = 1  # one hot encoding for sampled token\n",
    "\n",
    "            yield idx\n",
    "\n",
    "            if idx == self.eos_token_idx:  # stop sampling\n",
    "                break\n",
    "\n",
    "    def loss(self, inputs: list[int], targets: list[int], hprev=None):\n",
    "        \"\"\"\n",
    "        Computes loss between input and target chars idxes and returns\n",
    "        the loss, gradients (dWxh, dWhh, dWhy, dbh, dby), and final hidden state\n",
    "        \"\"\"\n",
    "        assert len(inputs) == len(targets)\n",
    "        xs, hs, ps = {}, {}, {}  # keep track of x, hidden states, and output probs\n",
    "        hs[-1] = (\n",
    "            hprev if hprev is not None else np.zeros((1, self.hidden_size))\n",
    "        )  # store initial hidden state\n",
    "        loss = 0\n",
    "\n",
    "        # forward pass\n",
    "        for t in range(len(inputs)):\n",
    "            x = np.zeros((1, self.vocab_size))\n",
    "            x[0, inputs[t]] = 1  # one hot encoding\n",
    "            p, h = self(x, hs[t - 1])  # rnn\n",
    "\n",
    "            xs[t] = x  # store x, hidden state, probs (we'll need them for backprop)\n",
    "            hs[t] = h\n",
    "            ps[t] = p\n",
    "            loss += -np.log(ps[t][0, targets[t]])\n",
    "\n",
    "        # gradient of loss w.r.t weights and biases\n",
    "        dWxh, dWhh, dWhy = (\n",
    "            np.zeros_like(self.Wxh),\n",
    "            np.zeros_like(self.Whh),\n",
    "            np.zeros_like(self.Why),\n",
    "        )\n",
    "        dbh, dby = np.zeros_like(self.bh), np.zeros_like(self.by)\n",
    "\n",
    "        # gradient of F_t (future loss L_t+1 ... L_T) w.r.t. h_t\n",
    "        dFdh = np.zeros((1, self.hidden_size))\n",
    "\n",
    "        # backprop thr. time\n",
    "        for t in reversed(range(len(inputs))):\n",
    "            dzy = np.copy(ps[t])  # loss at t w.r.t zy\n",
    "            dzy[:, targets[t]] -= 1\n",
    "\n",
    "            # 2nd layer\n",
    "            dWhy += dzy.T @ hs[t]\n",
    "            dby += dzy\n",
    "\n",
    "            # intermediate gradients\n",
    "            dLdh = dzy @ self.Why  # gradient of loss at L_t w.r.t hidden state h_t\n",
    "            dhdzh = 1 - hs[t] ** 2  # gradient thr. tanh activation\n",
    "            dFprevdh = dLdh + dFdh  # gradient of F_{t-1} w.r.t h_t\n",
    "            dFprevdzh = dFprevdh * dhdzh  # gradient of F_{t-1} w.r.t z_h\n",
    "\n",
    "            # 1st layer\n",
    "            dWxh += dFprevdzh.T @ xs[t]\n",
    "            dWhh += dFprevdzh.T @ hs[t - 1]\n",
    "            dbh += dFprevdzh\n",
    "\n",
    "            dFdh = dFprevdzh @ self.Whh  # update dFdh for next timestep t-1\n",
    "\n",
    "        gradients = (dWxh, dWhh, dWhy, dbh, dby)  # collect gradients\n",
    "        hnext = hs[len(inputs) - 1]  # final hidden state\n",
    "\n",
    "        return loss, gradients, hnext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path: str):\n",
    "    with open(path, \"r\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def build_vocab(data: str) -> str:\n",
    "    chars = set()\n",
    "    vocab = []\n",
    "    for char in data:\n",
    "        if char not in chars:\n",
    "            vocab.append(char)\n",
    "            chars.add(char)\n",
    "\n",
    "    return vocab\n",
    "\n",
    "def clip_gradients(gradients):\n",
    "    for gradient in gradients:\n",
    "        np.clip(gradient, -5, 5, out=gradient)  # clip gradient in-place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file(\"./weights/stevejobs.txt\")  # read txt file\n",
    "dataset = re.split(r\"\\n\\s*\\n\", data)  # split data into paragraphs\n",
    "vocab = build_vocab(data)  # build vocab of unique chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(\n",
    "    rnn: RNN,\n",
    "    dataset: list[str],\n",
    "    iters: int,\n",
    "    lr: float,\n",
    "    seq_length: int,\n",
    "    val_steps: int,\n",
    "    val_t: float,\n",
    "):\n",
    "    print(\"[INFO] Training...\")\n",
    "    print(f\"[INFO] data_size = {len(''.join(dataset))}\")\n",
    "    print(f\"[INFO] num_params = {rnn.num_params}\")\n",
    "    print(f\"[INFO] vocab_size = {rnn.vocab_size}\")\n",
    "    print(f\"[INFO] hidden_size = {rnn.hidden_size}\")\n",
    "    print(f\"[INFO] lr = {lr}\")\n",
    "    print(f\"[INFO] iters = {iters}\")\n",
    "    print(f\"[INFO] seq_length = {seq_length}\")\n",
    "\n",
    "    # memory variables for Adagrad\n",
    "    mWxh, mWhh, mWhy = (\n",
    "        np.zeros_like(rnn.Wxh),\n",
    "        np.zeros_like(rnn.Whh),\n",
    "        np.zeros_like(rnn.Why),\n",
    "    )\n",
    "    mbh, mby = np.zeros_like(rnn.bh), np.zeros_like(rnn.by)\n",
    "\n",
    "    n = 0\n",
    "    pbar = tqdm(total=iters, position=0)\n",
    "    smooth_loss = -np.log(1.0 / rnn.vocab_size) * seq_length  # loss at iteration 0\n",
    "    smooth_perplexity = 2**smooth_loss\n",
    "\n",
    "    while True:\n",
    "        batches = random.sample(dataset, len(dataset))\n",
    "        for minibatch in batches:\n",
    "            hprev = np.zeros((1, rnn.hidden_size))  # reset RNN memory\n",
    "            minibatch_idxs = rnn.encode(minibatch)\n",
    "\n",
    "            for p in range(0, len(minibatch), seq_length):\n",
    "                batch = minibatch_idxs[p : p + seq_length + 1]\n",
    "                inputs, targets = batch[:-1], batch[1:]\n",
    "\n",
    "                # compute loss and clip gradients\n",
    "                loss, gradients, hprev = rnn.loss(inputs, targets, hprev)\n",
    "                smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "                smooth_perplexity = 2**smooth_loss\n",
    "                clip_gradients(gradients)\n",
    "\n",
    "                # sample\n",
    "                if (n + 1) % val_steps == 0 or n == 0 or n == iters - 1:\n",
    "                    tqdm.write(\n",
    "                        f\"iter: {n + 1}, loss: {smooth_loss}, perplexity: {smooth_perplexity}\"\n",
    "                    )\n",
    "                    idxes = rnn.sample(val_t)\n",
    "                    txt = rnn.decode(idxes)\n",
    "                    tqdm.write(f\"----\\n{txt}\\n----\")\n",
    "                    tqdm.write(\"\")\n",
    "\n",
    "                # adagrad gradient descent\n",
    "                for param, dparam, mem in zip(\n",
    "                    rnn.weights,\n",
    "                    gradients,\n",
    "                    [mWxh, mWhh, mWhy, mbh, mby],\n",
    "                ):\n",
    "                    mem += dparam**2\n",
    "                    param += -lr * dparam / np.sqrt(mem + 1e-8)  # adagrad update\n",
    "\n",
    "                n += 1\n",
    "                pbar.update(1)\n",
    "\n",
    "                if n >= iters:\n",
    "                    break\n",
    "            if n >= iters:\n",
    "                break\n",
    "        if n >= iters:\n",
    "            break\n",
    "\n",
    "    print(\"[INFO] Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "iters = 100000\n",
    "lr = 1e-1\n",
    "seq_length = 25\n",
    "val_steps = 1000\n",
    "val_t = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(hidden_size=hidden_size, vocab=vocab)\n",
    "\n",
    "train_loop(\n",
    "    rnn=rnn,\n",
    "    dataset=dataset,\n",
    "    iters=iters,\n",
    "    lr=lr,\n",
    "    seq_length=seq_length,\n",
    "    val_steps=val_steps,\n",
    "    val_t=val_t,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m----> 2\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mrnn\u001b[49m\u001b[38;5;241m.\u001b[39msample(t\u001b[38;5;241m=\u001b[39mt)\n\u001b[1;32m      3\u001b[0m txt \u001b[38;5;241m=\u001b[39m rnn\u001b[38;5;241m.\u001b[39mdecode(sample)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(txt)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rnn' is not defined"
     ]
    }
   ],
   "source": [
    "t = 0.5\n",
    "sample = rnn.sample(t=t)\n",
    "txt = rnn.decode(sample)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnn-eNHe4zlT-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
